{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-51494129/ipykernel_2465696/3555461397.py:26: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  initialize(config_path=\"../configs\", job_name=\"job\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hydra.initialize()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import rootutils\n",
    "\n",
    "rootutils.setup_root(\"./\", indicator=\".project-root\", pythonpath=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import hydra\n",
    "import torch\n",
    "import torch_geometric\n",
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "from topobenchmarkx.data.preprocessor import PreProcessor\n",
    "from topobenchmarkx.dataloader.dataloader import TBXDataloader\n",
    "from topobenchmarkx.data.loaders import GraphLoader\n",
    "\n",
    "from topobenchmarkx.utils.config_resolvers import (\n",
    "    get_default_transform,\n",
    "    get_monitor_metric,\n",
    "    get_monitor_mode,\n",
    "    infer_in_channels,\n",
    ")\n",
    "\n",
    "\n",
    "initialize(config_path=\"../configs\", job_name=\"job\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = compose(config_name=\"run.yaml\", return_hydra_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_loader = GraphLoader(cfg.dataset.loader.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting /home/aj4332/Research/TopoBenchmarkX/datasets/graph/nyu/LanguageDataset/raw/LanguageDataset.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset, dataset_dir = graph_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniforge3/lib/python3.12/site-packages/torch_geometric/data/in_memory_dataset.py:300: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2495008"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.data.attention_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "attention_scores = []\n",
    "for token_list in dataset.data.tokens:\n",
    "    end_index = start_index + len(token_list) * len(token_list)\n",
    "    attention_scores_sentence = dataset.data.attention_scores[start_index:end_index]\n",
    "    start_index = end_index\n",
    "    attention_scores_sentence = torch.reshape(attention_scores_sentence, (len(token_list), len(token_list)))\n",
    "    attention_scores.append(attention_scores_sentence)\n",
    "tokens = dataset.data.tokens\n",
    "ids = dataset.data.ids\n",
    "tags = dataset.data.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_heads = 32\n",
    "num_sentences = len(ids)/num_heads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence we now have the following data.\n",
    "\n",
    "The length of each attribute is num_heads*num_sentences:\n",
    "1. tokens - each element is a list of length sentence_length\n",
    "2. ids - each element is a list of length sentence_length\n",
    "3. tags - each element is a list of length sentence_length\n",
    "4. attention_scores - each element is a tensor of shape (sentence_length, sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of tuple occurences\n",
    "graph_2s = []\n",
    "\n",
    "# the attention score threshold to consider relation between two tokens \n",
    "threshold = 0.0001\n",
    "\n",
    "# list of tokens to avoid in relations\n",
    "tokens_avoid = ['<|begin_of_text|>'.lower(), ''.lower()]\n",
    "\n",
    "# iterate over all sentences for all attention heads\n",
    "for sentence in range(len(tokens)):\n",
    "    \n",
    "    current_attention = attention_scores[sentence]\n",
    "    current_tokens = tokens[sentence]\n",
    "    \n",
    "    for row in range(len(current_attention)):\n",
    "        \n",
    "        for col in range(0,row+1):\n",
    "            \n",
    "            if row != col and current_attention[row][col] >= threshold:\n",
    "                word1 = current_tokens[row].lower().strip()\n",
    "                word2 = current_tokens[col].lower().strip()\n",
    "                \n",
    "                # Skip tokens that are empty or beginning of text indicators\n",
    "                if word1 in tokens_avoid or word2 in tokens_avoid or word1.isnumeric() or word2.isnumeric():\n",
    "                    continue\n",
    "                relation = ()\n",
    "                \n",
    "                # Create an ordered tuple for consistency\n",
    "                if word1 < word2:\n",
    "                    relation = (word1,word2)\n",
    "                else:\n",
    "                    relation = (word2,word1)\n",
    "\n",
    "                graph_2s.append(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1001569\n"
     ]
    }
   ],
   "source": [
    "print(len(graph_2s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "counter=collections.Counter(graph_2s)\n",
    "# print(collections.OrderedDict(sorted(counter.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [4.6254e-01, 5.3746e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [4.2101e-01, 9.7475e-02, 4.8151e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [3.7420e-01, 3.1179e-02, 1.3714e-01, 4.5748e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [7.7811e-01, 6.8530e-04, 2.6457e-03, 9.0795e-02, 1.2776e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [4.3133e-01, 1.2016e-02, 1.0733e-02, 2.8916e-02, 5.1130e-02, 4.6587e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [4.2843e-01, 6.6626e-03, 1.3055e-02, 4.7056e-03, 8.4519e-03, 5.4083e-02,\n",
       "         4.8461e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [3.4764e-01, 4.0452e-03, 7.2805e-03, 2.3914e-03, 2.3553e-03, 1.1718e-02,\n",
       "         8.1760e-02, 5.4281e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [3.1476e-01, 2.0011e-03, 2.3785e-03, 1.5471e-03, 1.1528e-03, 3.4818e-03,\n",
       "         1.0619e-02, 7.0552e-02, 5.9350e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.4278e-01, 7.1517e-04, 1.0854e-03, 1.0017e-03, 9.2751e-04, 3.2553e-03,\n",
       "         8.7617e-03, 3.3378e-02, 1.6144e-01, 5.4666e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.9087e-01, 6.9281e-04, 4.4001e-04, 4.2536e-04, 6.8224e-04, 2.7703e-03,\n",
       "         6.2806e-03, 8.4009e-03, 2.3959e-02, 1.0328e-01, 6.6220e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.6753e-01, 1.2780e-03, 1.1696e-03, 5.4049e-04, 6.3220e-04, 1.7825e-03,\n",
       "         1.7669e-02, 2.9694e-02, 2.0154e-02, 9.8352e-02, 2.4472e-02, 5.3673e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [3.6325e-01, 5.5352e-03, 2.4752e-03, 1.3191e-03, 7.2738e-04, 1.9392e-03,\n",
       "         2.6853e-02, 2.4892e-02, 4.7821e-03, 1.0479e-02, 4.9252e-03, 9.6939e-02,\n",
       "         4.5588e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.6703e-01, 1.6259e-03, 1.4267e-03, 1.3090e-03, 3.7643e-04, 2.8772e-03,\n",
       "         9.6214e-03, 1.2213e-02, 6.2202e-03, 1.1960e-02, 4.8540e-03, 4.2025e-02,\n",
       "         1.3978e-01, 4.9869e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [3.0759e-01, 7.9129e-03, 2.2542e-03, 3.4622e-03, 1.7779e-03, 3.1254e-03,\n",
       "         5.0459e-03, 6.2305e-03, 2.1069e-03, 1.4180e-02, 5.0137e-03, 5.9892e-02,\n",
       "         4.2519e-02, 7.6097e-02, 4.6279e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [3.3704e-01, 1.2920e-03, 4.2633e-04, 6.5452e-04, 9.0092e-04, 1.3439e-03,\n",
       "         1.6715e-03, 2.3698e-03, 8.0440e-04, 2.3760e-03, 1.6231e-03, 6.2169e-03,\n",
       "         1.3391e-02, 1.8584e-02, 1.2125e-01, 4.9005e-01, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.6125e-01, 1.1021e-03, 2.1557e-04, 2.3425e-04, 2.5149e-04, 3.0074e-03,\n",
       "         2.6816e-03, 2.7123e-03, 6.8079e-04, 2.1213e-03, 2.8233e-04, 1.4818e-02,\n",
       "         7.3490e-03, 7.4933e-03, 8.6302e-02, 6.1475e-02, 5.4802e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [1.9283e-01, 1.3986e-03, 4.8067e-04, 3.7613e-04, 2.4888e-04, 4.0859e-03,\n",
       "         2.7159e-03, 4.0854e-03, 1.9484e-03, 3.5240e-03, 1.4965e-03, 1.2528e-02,\n",
       "         9.0609e-03, 8.3385e-03, 1.8343e-02, 3.0147e-02, 1.0601e-01, 6.0238e-01,\n",
       "         0.0000e+00, 0.0000e+00],\n",
       "        [2.3280e-01, 1.0317e-03, 4.3144e-04, 2.1228e-04, 2.3688e-04, 1.1032e-03,\n",
       "         1.7312e-03, 1.9840e-03, 1.1670e-03, 9.0450e-04, 1.2566e-03, 2.3647e-03,\n",
       "         2.1894e-03, 5.1913e-03, 6.5635e-03, 9.9111e-03, 1.7750e-02, 7.8872e-02,\n",
       "         6.3430e-01, 0.0000e+00],\n",
       "        [2.6816e-01, 7.8938e-04, 5.0931e-04, 3.1422e-04, 1.7340e-04, 1.5555e-03,\n",
       "         1.0228e-03, 2.1595e-03, 2.4593e-03, 7.7517e-03, 6.0901e-04, 2.3456e-02,\n",
       "         5.5981e-03, 8.5362e-03, 6.3944e-02, 2.5942e-02, 9.3970e-02, 2.0980e-02,\n",
       "         4.7699e-02, 4.2437e-01]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of tuple occurences\n",
    "attention_head = 0\n",
    "graph_2s_head = []\n",
    "\n",
    "# the attention score threshold to consider relation between two tokens \n",
    "threshold = 0.0001\n",
    "\n",
    "# list of tokens to avoid in relations\n",
    "tokens_avoid = ['<|begin_of_text|>'.lower(), ''.lower()]\n",
    "\n",
    "# iterate over all sentences for the first attention head\n",
    "for sentence in range(attention_head,len(tokens), num_heads):\n",
    "    \n",
    "    current_attention = attention_scores[sentence]\n",
    "    current_tokens = tokens[sentence]\n",
    "    \n",
    "    for row in range(len(current_attention)):\n",
    "        \n",
    "        for col in range(0,row+1):\n",
    "            \n",
    "            if row != col and current_attention[row][col] >= threshold:\n",
    "                word1 = current_tokens[row].lower().strip()\n",
    "                word2 = current_tokens[col].lower().strip()\n",
    "                \n",
    "                # Skip tokens that are empty or beginning of text indicators\n",
    "                if word1 in tokens_avoid or word2 in tokens_avoid or word1.isnumeric() or word2.isnumeric():\n",
    "                    continue\n",
    "                relation = ()\n",
    "                \n",
    "                # Create an ordered tuple for consistency\n",
    "                if word1 < word2:\n",
    "                    relation = (word1,word2)\n",
    "                else:\n",
    "                    relation = (word2,word1)\n",
    "\n",
    "                graph_2s_head.append(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32672\n"
     ]
    }
   ],
   "source": [
    "print(len(graph_2s_head))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "counter2=collections.Counter(graph_2s_head)\n",
    "# print(collections.OrderedDict(sorted(counter2.items())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
